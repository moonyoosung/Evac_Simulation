Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
100000,1.571735,93.10731244064577,2.91389,4.8146814859604,4.8146814859604,5.1719155,0.09599764,0.00029699501,0.2979967,0.0049500177,1.0
200000,0.9976954,91.88,3.9900672,5.458576813881795,5.458576813881795,3.1586347,0.09578766,0.00029099797,0.29399863,0.0048502656,1.0
300000,0.5782135,94.96267942583732,3.6495118,4.953562174394456,4.953562174394456,3.7890177,0.09795226,0.00028499917,0.28999946,0.004750487,1.0
400000,0.38210946,97.98906560636183,3.6522007,4.898435663750347,4.898435663750347,3.71672,0.09730632,0.00027899412,0.28599608,0.0046506017,1.0
