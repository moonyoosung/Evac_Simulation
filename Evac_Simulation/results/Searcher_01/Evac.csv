Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
50000,1.7610458,176.44802867383513,-0.89028347,-17.71333566440209,-17.71333566440209,2.935002,0.025619507,0.0002845911,0.1948637,0.004743698,1.0
100000,1.6298323,177.38078291814946,-2.174357,-9.34671880624124,-9.34671880624124,1.3904854,0.025394922,0.00025686494,0.18562165,0.004282519,1.0
150000,1.49244,195.9448818897638,-2.064438,-2.0149103011208354,-2.0149103011208354,0.24462748,0.025273677,0.00022607669,0.17535892,0.003770408,1.0
200000,1.3699394,196.0197628458498,-1.38893,-1.1883518559335484,-1.1883518559335484,0.04656712,0.022950092,0.0001952943,0.16509807,0.003258394,1.0
250000,1.2699261,196.7905138339921,-0.9336046,-1.0657471077803802,-1.0657471077803802,0.06186527,0.022412647,0.00016452163,0.15484054,0.0027465422,1.0
